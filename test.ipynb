{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/pyz/miniconda/envs/leverlm/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    CLIPTextModelWithProjection,\n",
    "    CLIPVisionModelWithProjection,\n",
    "    GPT2Config,\n",
    "    GPT2LMHeadModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=118287+3,\n",
    "    n_embd=512,\n",
    "    n_head=8,\n",
    "    n_layer=2,\n",
    "    eos_token_id=118287,\n",
    "    bos_token_id=118287 + 1,\n",
    ")\n",
    "lm_model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total -  67394560\n",
      "Trainable -  67394560\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in lm_model.parameters())\n",
    "trainable_pytorch_total_params = sum(p.numel() for p in lm_model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Total - ', pytorch_total_params)\n",
    "print('Trainable - ', trainable_pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b0375bfd2b4e65956df9c925ba85a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flamingo model initialized with 1384781840 trainable parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['vision_encoder.class_embedding', 'vision_encoder.positional_embedding', 'vision_encoder.proj', 'vision_encoder.conv1.weight', 'vision_encoder.ln_pre.weight', 'vision_encoder.ln_pre.bias', 'vision_encoder.transformer.resblocks.0.ln_1.weight', 'vision_encoder.transformer.resblocks.0.ln_1.bias', 'vision_encoder.transformer.resblocks.0.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.0.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.0.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.0.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.0.ln_2.weight', 'vision_encoder.transformer.resblocks.0.ln_2.bias', 'vision_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.1.ln_1.weight', 'vision_encoder.transformer.resblocks.1.ln_1.bias', 'vision_encoder.transformer.resblocks.1.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.1.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.1.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.1.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.1.ln_2.weight', 'vision_encoder.transformer.resblocks.1.ln_2.bias', 'vision_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.2.ln_1.weight', 'vision_encoder.transformer.resblocks.2.ln_1.bias', 'vision_encoder.transformer.resblocks.2.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.2.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.2.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.2.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.2.ln_2.weight', 'vision_encoder.transformer.resblocks.2.ln_2.bias', 'vision_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.3.ln_1.weight', 'vision_encoder.transformer.resblocks.3.ln_1.bias', 'vision_encoder.transformer.resblocks.3.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.3.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.3.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.3.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.3.ln_2.weight', 'vision_encoder.transformer.resblocks.3.ln_2.bias', 'vision_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.4.ln_1.weight', 'vision_encoder.transformer.resblocks.4.ln_1.bias', 'vision_encoder.transformer.resblocks.4.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.4.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.4.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.4.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.4.ln_2.weight', 'vision_encoder.transformer.resblocks.4.ln_2.bias', 'vision_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.5.ln_1.weight', 'vision_encoder.transformer.resblocks.5.ln_1.bias', 'vision_encoder.transformer.resblocks.5.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.5.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.5.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.5.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.5.ln_2.weight', 'vision_encoder.transformer.resblocks.5.ln_2.bias', 'vision_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.6.ln_1.weight', 'vision_encoder.transformer.resblocks.6.ln_1.bias', 'vision_encoder.transformer.resblocks.6.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.6.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.6.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.6.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.6.ln_2.weight', 'vision_encoder.transformer.resblocks.6.ln_2.bias', 'vision_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.7.ln_1.weight', 'vision_encoder.transformer.resblocks.7.ln_1.bias', 'vision_encoder.transformer.resblocks.7.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.7.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.7.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.7.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.7.ln_2.weight', 'vision_encoder.transformer.resblocks.7.ln_2.bias', 'vision_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.8.ln_1.weight', 'vision_encoder.transformer.resblocks.8.ln_1.bias', 'vision_encoder.transformer.resblocks.8.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.8.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.8.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.8.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.8.ln_2.weight', 'vision_encoder.transformer.resblocks.8.ln_2.bias', 'vision_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.9.ln_1.weight', 'vision_encoder.transformer.resblocks.9.ln_1.bias', 'vision_encoder.transformer.resblocks.9.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.9.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.9.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.9.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.9.ln_2.weight', 'vision_encoder.transformer.resblocks.9.ln_2.bias', 'vision_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.10.ln_1.weight', 'vision_encoder.transformer.resblocks.10.ln_1.bias', 'vision_encoder.transformer.resblocks.10.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.10.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.10.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.10.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.10.ln_2.weight', 'vision_encoder.transformer.resblocks.10.ln_2.bias', 'vision_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.11.ln_1.weight', 'vision_encoder.transformer.resblocks.11.ln_1.bias', 'vision_encoder.transformer.resblocks.11.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.11.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.11.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.11.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.11.ln_2.weight', 'vision_encoder.transformer.resblocks.11.ln_2.bias', 'vision_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.12.ln_1.weight', 'vision_encoder.transformer.resblocks.12.ln_1.bias', 'vision_encoder.transformer.resblocks.12.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.12.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.12.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.12.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.12.ln_2.weight', 'vision_encoder.transformer.resblocks.12.ln_2.bias', 'vision_encoder.transformer.resblocks.12.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.12.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.12.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.12.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.13.ln_1.weight', 'vision_encoder.transformer.resblocks.13.ln_1.bias', 'vision_encoder.transformer.resblocks.13.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.13.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.13.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.13.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.13.ln_2.weight', 'vision_encoder.transformer.resblocks.13.ln_2.bias', 'vision_encoder.transformer.resblocks.13.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.13.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.13.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.13.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.14.ln_1.weight', 'vision_encoder.transformer.resblocks.14.ln_1.bias', 'vision_encoder.transformer.resblocks.14.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.14.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.14.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.14.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.14.ln_2.weight', 'vision_encoder.transformer.resblocks.14.ln_2.bias', 'vision_encoder.transformer.resblocks.14.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.14.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.14.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.14.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.15.ln_1.weight', 'vision_encoder.transformer.resblocks.15.ln_1.bias', 'vision_encoder.transformer.resblocks.15.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.15.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.15.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.15.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.15.ln_2.weight', 'vision_encoder.transformer.resblocks.15.ln_2.bias', 'vision_encoder.transformer.resblocks.15.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.15.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.15.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.15.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.16.ln_1.weight', 'vision_encoder.transformer.resblocks.16.ln_1.bias', 'vision_encoder.transformer.resblocks.16.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.16.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.16.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.16.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.16.ln_2.weight', 'vision_encoder.transformer.resblocks.16.ln_2.bias', 'vision_encoder.transformer.resblocks.16.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.16.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.16.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.16.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.17.ln_1.weight', 'vision_encoder.transformer.resblocks.17.ln_1.bias', 'vision_encoder.transformer.resblocks.17.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.17.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.17.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.17.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.17.ln_2.weight', 'vision_encoder.transformer.resblocks.17.ln_2.bias', 'vision_encoder.transformer.resblocks.17.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.17.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.17.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.17.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.18.ln_1.weight', 'vision_encoder.transformer.resblocks.18.ln_1.bias', 'vision_encoder.transformer.resblocks.18.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.18.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.18.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.18.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.18.ln_2.weight', 'vision_encoder.transformer.resblocks.18.ln_2.bias', 'vision_encoder.transformer.resblocks.18.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.18.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.18.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.18.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.19.ln_1.weight', 'vision_encoder.transformer.resblocks.19.ln_1.bias', 'vision_encoder.transformer.resblocks.19.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.19.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.19.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.19.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.19.ln_2.weight', 'vision_encoder.transformer.resblocks.19.ln_2.bias', 'vision_encoder.transformer.resblocks.19.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.19.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.19.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.19.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.20.ln_1.weight', 'vision_encoder.transformer.resblocks.20.ln_1.bias', 'vision_encoder.transformer.resblocks.20.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.20.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.20.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.20.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.20.ln_2.weight', 'vision_encoder.transformer.resblocks.20.ln_2.bias', 'vision_encoder.transformer.resblocks.20.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.20.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.20.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.20.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.21.ln_1.weight', 'vision_encoder.transformer.resblocks.21.ln_1.bias', 'vision_encoder.transformer.resblocks.21.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.21.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.21.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.21.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.21.ln_2.weight', 'vision_encoder.transformer.resblocks.21.ln_2.bias', 'vision_encoder.transformer.resblocks.21.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.21.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.21.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.21.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.22.ln_1.weight', 'vision_encoder.transformer.resblocks.22.ln_1.bias', 'vision_encoder.transformer.resblocks.22.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.22.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.22.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.22.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.22.ln_2.weight', 'vision_encoder.transformer.resblocks.22.ln_2.bias', 'vision_encoder.transformer.resblocks.22.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.22.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.22.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.22.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.23.ln_1.weight', 'vision_encoder.transformer.resblocks.23.ln_1.bias', 'vision_encoder.transformer.resblocks.23.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.23.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.23.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.23.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.23.ln_2.weight', 'vision_encoder.transformer.resblocks.23.ln_2.bias', 'vision_encoder.transformer.resblocks.23.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.23.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.23.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.23.mlp.c_proj.bias', 'vision_encoder.ln_post.weight', 'vision_encoder.ln_post.bias', 'lang_encoder.transformer.blocks.0.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.norm_f.weight', 'lang_encoder.old_decoder_blocks.0.norm_1.weight', 'lang_encoder.old_decoder_blocks.0.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.0.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.0.norm_2.weight', 'lang_encoder.old_decoder_blocks.0.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.0.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.1.norm_1.weight', 'lang_encoder.old_decoder_blocks.1.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.1.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.1.norm_2.weight', 'lang_encoder.old_decoder_blocks.1.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.1.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.2.norm_1.weight', 'lang_encoder.old_decoder_blocks.2.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.2.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.2.norm_2.weight', 'lang_encoder.old_decoder_blocks.2.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.2.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.3.norm_1.weight', 'lang_encoder.old_decoder_blocks.3.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.3.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.3.norm_2.weight', 'lang_encoder.old_decoder_blocks.3.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.3.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.4.norm_1.weight', 'lang_encoder.old_decoder_blocks.4.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.4.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.4.norm_2.weight', 'lang_encoder.old_decoder_blocks.4.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.4.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.5.norm_1.weight', 'lang_encoder.old_decoder_blocks.5.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.5.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.5.norm_2.weight', 'lang_encoder.old_decoder_blocks.5.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.5.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.6.norm_1.weight', 'lang_encoder.old_decoder_blocks.6.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.6.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.6.norm_2.weight', 'lang_encoder.old_decoder_blocks.6.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.6.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.7.norm_1.weight', 'lang_encoder.old_decoder_blocks.7.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.7.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.7.norm_2.weight', 'lang_encoder.old_decoder_blocks.7.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.7.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.8.norm_1.weight', 'lang_encoder.old_decoder_blocks.8.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.8.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.8.norm_2.weight', 'lang_encoder.old_decoder_blocks.8.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.8.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.9.norm_1.weight', 'lang_encoder.old_decoder_blocks.9.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.9.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.9.norm_2.weight', 'lang_encoder.old_decoder_blocks.9.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.9.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.10.norm_1.weight', 'lang_encoder.old_decoder_blocks.10.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.10.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.10.norm_2.weight', 'lang_encoder.old_decoder_blocks.10.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.10.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.11.norm_1.weight', 'lang_encoder.old_decoder_blocks.11.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.11.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.11.norm_2.weight', 'lang_encoder.old_decoder_blocks.11.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.11.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.12.norm_1.weight', 'lang_encoder.old_decoder_blocks.12.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.12.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.12.norm_2.weight', 'lang_encoder.old_decoder_blocks.12.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.12.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.13.norm_1.weight', 'lang_encoder.old_decoder_blocks.13.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.13.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.13.norm_2.weight', 'lang_encoder.old_decoder_blocks.13.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.13.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.14.norm_1.weight', 'lang_encoder.old_decoder_blocks.14.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.14.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.14.norm_2.weight', 'lang_encoder.old_decoder_blocks.14.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.14.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.15.norm_1.weight', 'lang_encoder.old_decoder_blocks.15.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.15.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.15.norm_2.weight', 'lang_encoder.old_decoder_blocks.15.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.15.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.16.norm_1.weight', 'lang_encoder.old_decoder_blocks.16.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.16.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.16.norm_2.weight', 'lang_encoder.old_decoder_blocks.16.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.16.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.17.norm_1.weight', 'lang_encoder.old_decoder_blocks.17.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.17.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.17.norm_2.weight', 'lang_encoder.old_decoder_blocks.17.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.17.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.18.norm_1.weight', 'lang_encoder.old_decoder_blocks.18.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.18.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.18.norm_2.weight', 'lang_encoder.old_decoder_blocks.18.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.18.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.19.norm_1.weight', 'lang_encoder.old_decoder_blocks.19.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.19.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.19.norm_2.weight', 'lang_encoder.old_decoder_blocks.19.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.19.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.20.norm_1.weight', 'lang_encoder.old_decoder_blocks.20.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.20.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.20.norm_2.weight', 'lang_encoder.old_decoder_blocks.20.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.20.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.21.norm_1.weight', 'lang_encoder.old_decoder_blocks.21.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.21.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.21.norm_2.weight', 'lang_encoder.old_decoder_blocks.21.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.21.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.22.norm_1.weight', 'lang_encoder.old_decoder_blocks.22.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.22.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.22.norm_2.weight', 'lang_encoder.old_decoder_blocks.22.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.22.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.23.norm_1.weight', 'lang_encoder.old_decoder_blocks.23.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.23.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.23.norm_2.weight', 'lang_encoder.old_decoder_blocks.23.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.23.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.24.norm_1.weight', 'lang_encoder.old_decoder_blocks.24.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.24.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.24.norm_2.weight', 'lang_encoder.old_decoder_blocks.24.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.24.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.25.norm_1.weight', 'lang_encoder.old_decoder_blocks.25.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.25.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.25.norm_2.weight', 'lang_encoder.old_decoder_blocks.25.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.25.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.26.norm_1.weight', 'lang_encoder.old_decoder_blocks.26.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.26.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.26.norm_2.weight', 'lang_encoder.old_decoder_blocks.26.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.26.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.27.norm_1.weight', 'lang_encoder.old_decoder_blocks.27.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.27.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.27.norm_2.weight', 'lang_encoder.old_decoder_blocks.27.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.27.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.28.norm_1.weight', 'lang_encoder.old_decoder_blocks.28.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.28.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.28.norm_2.weight', 'lang_encoder.old_decoder_blocks.28.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.28.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.29.norm_1.weight', 'lang_encoder.old_decoder_blocks.29.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.29.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.29.norm_2.weight', 'lang_encoder.old_decoder_blocks.29.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.29.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.30.norm_1.weight', 'lang_encoder.old_decoder_blocks.30.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.30.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.30.norm_2.weight', 'lang_encoder.old_decoder_blocks.30.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.30.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.31.norm_1.weight', 'lang_encoder.old_decoder_blocks.31.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.31.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.31.norm_2.weight', 'lang_encoder.old_decoder_blocks.31.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.31.ffn.down_proj.weight', 'lang_encoder.gated_cross_attn_layers.3.attn_gate', 'lang_encoder.gated_cross_attn_layers.3.ff_gate', 'lang_encoder.gated_cross_attn_layers.3.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.3.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.3.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.7.attn_gate', 'lang_encoder.gated_cross_attn_layers.7.ff_gate', 'lang_encoder.gated_cross_attn_layers.7.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.7.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.7.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.11.attn_gate', 'lang_encoder.gated_cross_attn_layers.11.ff_gate', 'lang_encoder.gated_cross_attn_layers.11.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.11.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.11.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.15.attn_gate', 'lang_encoder.gated_cross_attn_layers.15.ff_gate', 'lang_encoder.gated_cross_attn_layers.15.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.15.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.15.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.19.attn_gate', 'lang_encoder.gated_cross_attn_layers.19.ff_gate', 'lang_encoder.gated_cross_attn_layers.19.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.19.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.19.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.23.attn_gate', 'lang_encoder.gated_cross_attn_layers.23.ff_gate', 'lang_encoder.gated_cross_attn_layers.23.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.23.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.23.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.27.attn_gate', 'lang_encoder.gated_cross_attn_layers.27.ff_gate', 'lang_encoder.gated_cross_attn_layers.27.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.27.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.27.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.31.attn_gate', 'lang_encoder.gated_cross_attn_layers.31.ff_gate', 'lang_encoder.gated_cross_attn_layers.31.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.31.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.31.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.3.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from open_flamingo import create_model_and_transforms\n",
    "import os\n",
    "\n",
    "model_dir = '/data/share/pyz/model_weight'\n",
    "\n",
    "model, image_processor, tokenizer = create_model_and_transforms(\n",
    "    clip_vision_encoder_path=\"ViT-L-14\",\n",
    "    clip_vision_encoder_pretrained=\"openai\",\n",
    "    lang_encoder_path=\"anas-awadalla/mpt-7b\",\n",
    "    tokenizer_path=\"anas-awadalla/mpt-7b\",\n",
    "    cross_attn_every_n_layers=4\n",
    ")\n",
    "\n",
    "# grab model checkpoint from huggingface hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "\n",
    "checkpoint_path = os.path.join(model_dir, \"OpenFlamingo-9B-vitl-mpt7b\", \"checkpoint.pt\")\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import TraceDict\n",
    "torch.set_grad_enabled(False)\n",
    "model = model.to('cuda:3', torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "Step 1: Load images\n",
    "\"\"\"\n",
    "demo_image_one = Image.open(\n",
    "    requests.get(\n",
    "        \"http://images.cocodataset.org/val2017/000000039769.jpg\", stream=True\n",
    "    ).raw\n",
    ")\n",
    "\n",
    "demo_image_two = Image.open(\n",
    "    requests.get(\n",
    "        \"http://images.cocodataset.org/test-stuff2017/000000028137.jpg\",\n",
    "        stream=True\n",
    "    ).raw\n",
    ")\n",
    "\n",
    "query_image = Image.open(\n",
    "    requests.get(\n",
    "        \"http://images.cocodataset.org/test-stuff2017/000000028352.jpg\", \n",
    "        stream=True\n",
    "    ).raw\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 2: Preprocessing images\n",
    "Details: For OpenFlamingo, we expect the image to be a torch tensor of shape \n",
    " batch_size x num_media x num_frames x channels x height x width. \n",
    " In this case batch_size = 1, num_media = 3, num_frames = 1,\n",
    " channels = 3, height = 224, width = 224.\n",
    "\"\"\"\n",
    "vision_x = [image_processor(demo_image_one).unsqueeze(0), image_processor(demo_image_two).unsqueeze(0), image_processor(query_image).unsqueeze(0)]\n",
    "vision_x = torch.cat(vision_x, dim=0)\n",
    "vision_x = vision_x.unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "\"\"\"\n",
    "Step 3: Preprocessing text\n",
    "Details: In the text we expect an <image> special token to indicate where an image is.\n",
    " We also expect an <|endofchunk|> special token to indicate the end of the text \n",
    " portion associated with an image.\n",
    "\"\"\"\n",
    "tokenizer.padding_side = \"left\" # For generation padding tokens should be on the left\n",
    "lang_x = tokenizer(\n",
    "    [\"<image>An image of two cats.<|endofchunk|><image>An image of a bathroom sink.<|endofchunk|><image>An image of\"],\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 4: Generate text\n",
    "\"\"\"\n",
    "generated_text = model.generate(\n",
    "        vision_x=vision_x.to(\"cuda:3\", torch.bfloat16),\n",
    "        lang_x=lang_x[\"input_ids\"].to(\"cuda:3\"),\n",
    "        attention_mask=lang_x[\"attention_mask\"].to(\"cuda:3\"),\n",
    "    max_new_tokens=20,\n",
    "    num_beams=3,\n",
    ")\n",
    "\n",
    "print(\"Generated text: \", tokenizer.decode(generated_text[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leverlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
